{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "a21ebb03-f0f1-46b1-8608-b34231a8c278",
      "metadata": {
        "id": "a21ebb03-f0f1-46b1-8608-b34231a8c278"
      },
      "source": [
        "# Example on a MNIST GAN with PyTorch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!nvidia-smi\n",
        "\n",
        "project = '/content/drive/MyDrive/mnist-gan'\n",
        "%mkdir -p {project}"
      ],
      "metadata": {
        "id": "0KfI-q7_isVO"
      },
      "id": "0KfI-q7_isVO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6a3c0dde-9ffa-4784-847b-8b8a347f5aea",
      "metadata": {
        "id": "6a3c0dde-9ffa-4784-847b-8b8a347f5aea"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "746ad691-29b6-401f-a7cb-e257942d3ad4",
      "metadata": {
        "id": "746ad691-29b6-401f-a7cb-e257942d3ad4"
      },
      "outputs": [],
      "source": [
        "bs = 128  # batch size\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    #transforms.Normalize(mean=(0.5,), std=(0.5,))\n",
        "    #transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "# MNIST contains 60000 images\n",
        "train_dataset = datasets.MNIST(root='.', train=True, transform=transform, download=True)\n",
        "#test_dataset = datasets.MNIST(root='.', train=False, transform=transform, download=False)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=bs, shuffle=True, drop_last=True)\n",
        "#test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=bs, shuffle=False, drop_last=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bf18110d-b437-4a05-a4b8-3e32f66525d6",
      "metadata": {
        "id": "bf18110d-b437-4a05-a4b8-3e32f66525d6"
      },
      "outputs": [],
      "source": [
        "z_dim = 100\n",
        "mnist_dim = train_dataset.data.size(1) * train_dataset.data.size(2)\n",
        "\n",
        "print(z_dim)\n",
        "print(mnist_dim)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eec1d2c5-fcf1-4a9b-ac4d-f742649467af",
      "metadata": {
        "id": "eec1d2c5-fcf1-4a9b-ac4d-f742649467af"
      },
      "source": [
        "## Generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "31f87489-4872-4697-a220-50786e0da7de",
      "metadata": {
        "id": "31f87489-4872-4697-a220-50786e0da7de"
      },
      "outputs": [],
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self, g_input_dim, g_output_dim):\n",
        "        super(Generator, self).__init__()       \n",
        "        self.fc1 = nn.Linear(g_input_dim, 256)\n",
        "        self.fc2 = nn.Linear(self.fc1.out_features, self.fc1.out_features * 2)\n",
        "        self.fc3 = nn.Linear(self.fc2.out_features, self.fc2.out_features * 2)\n",
        "        self.fc4 = nn.Linear(self.fc3.out_features, g_output_dim)\n",
        "    \n",
        "    def forward(self, x): \n",
        "        x = F.leaky_relu(self.fc1(x), 0.2)\n",
        "        x = F.leaky_relu(self.fc2(x), 0.2)\n",
        "        x = F.leaky_relu(self.fc3(x), 0.2)\n",
        "        return torch.tanh(self.fc4(x))\n",
        "    \n",
        "G = Generator(g_input_dim = z_dim, g_output_dim = mnist_dim).to(device)\n",
        "print(G)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4eff3b92-f6fd-4f12-9de6-8411d4abaedd",
      "metadata": {
        "id": "4eff3b92-f6fd-4f12-9de6-8411d4abaedd"
      },
      "source": [
        "## Discriminator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0b2cf6a0-5c8d-4dfc-9107-44cd6d9b5460",
      "metadata": {
        "id": "0b2cf6a0-5c8d-4dfc-9107-44cd6d9b5460"
      },
      "outputs": [],
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, d_input_dim):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.fc1 = nn.Linear(d_input_dim, 1024)\n",
        "        self.fc2 = nn.Linear(self.fc1.out_features, self.fc1.out_features // 2)\n",
        "        self.fc3 = nn.Linear(self.fc2.out_features, self.fc2.out_features // 2)\n",
        "        self.fc4 = nn.Linear(self.fc3.out_features, 1)\n",
        "    \n",
        "    # forward method\n",
        "    def forward(self, x):\n",
        "        x = F.leaky_relu(self.fc1(x), 0.2)\n",
        "        x = F.dropout(x, 0.3)\n",
        "        x = F.leaky_relu(self.fc2(x), 0.2)\n",
        "        x = F.dropout(x, 0.3)\n",
        "        x = F.leaky_relu(self.fc3(x), 0.2)\n",
        "        x = F.dropout(x, 0.3)\n",
        "        return torch.sigmoid(self.fc4(x))\n",
        "\n",
        "D = Discriminator(mnist_dim).to(device)\n",
        "print(D)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "75037eb3-10e9-4767-ae0d-2d3b6d356b8c",
      "metadata": {
        "id": "75037eb3-10e9-4767-ae0d-2d3b6d356b8c"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c746454-6ba1-421d-926e-e944a66035fd",
      "metadata": {
        "id": "3c746454-6ba1-421d-926e-e944a66035fd"
      },
      "outputs": [],
      "source": [
        "# loss function\n",
        "criterion = nn.BCELoss() \n",
        "\n",
        "# optimizer\n",
        "lr = 0.00001\n",
        "G_optimizer = optim.Adam(G.parameters(), lr = lr)\n",
        "D_optimizer = optim.Adam(D.parameters(), lr = lr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2496ae02-6694-43bc-89b5-f8ff542b56c2",
      "metadata": {
        "id": "2496ae02-6694-43bc-89b5-f8ff542b56c2"
      },
      "outputs": [],
      "source": [
        "def D_train(x):\n",
        "    D.zero_grad()\n",
        "\n",
        "    # train discriminator on real\n",
        "    x_real, y_real = x.view(-1, mnist_dim), torch.ones(bs, 1)\n",
        "    x_real, y_real = x_real.to(device), y_real.to(device)\n",
        "\n",
        "    D_output = D(x_real)\n",
        "    D_real_loss = criterion(D_output, y_real)\n",
        "    D_real_score = D_output\n",
        "\n",
        "    # train discriminator on fake\n",
        "    z = torch.randn(bs, z_dim).to(device)\n",
        "    x_fake, y_fake = G(z), torch.zeros(bs, 1).to(device)\n",
        "\n",
        "    D_output = D(x_fake)\n",
        "    D_fake_loss = criterion(D_output, y_fake)\n",
        "    D_fake_score = D_output\n",
        "\n",
        "    # gradient backprop & optimize ONLY D's parameters\n",
        "    D_loss = D_real_loss + D_fake_loss\n",
        "    D_loss.backward()\n",
        "    D_optimizer.step()\n",
        "        \n",
        "    return  D_loss.data.item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3dd82c46-698b-4cc6-926e-31e93111f528",
      "metadata": {
        "id": "3dd82c46-698b-4cc6-926e-31e93111f528"
      },
      "outputs": [],
      "source": [
        "def G_train(x):\n",
        "    G.zero_grad()\n",
        "\n",
        "    z = torch.randn(bs, z_dim).to(device)\n",
        "    y = torch.ones(bs, 1).to(device)\n",
        "\n",
        "    G_output = G(z)\n",
        "    D_output = D(G_output)\n",
        "    G_loss = criterion(D_output, y)\n",
        "\n",
        "    # gradient backprop & optimize ONLY G's parameters\n",
        "    G_loss.backward()\n",
        "    G_optimizer.step()\n",
        "        \n",
        "    return G_loss.data.item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "69c24f7f-badc-4824-9e7c-72900282e815",
      "metadata": {
        "id": "69c24f7f-badc-4824-9e7c-72900282e815"
      },
      "outputs": [],
      "source": [
        "%load_ext tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e0b410b1-f638-42b1-90e2-ac3d091bea5b",
      "metadata": {
        "id": "e0b410b1-f638-42b1-90e2-ac3d091bea5b"
      },
      "outputs": [],
      "source": [
        "%mkdir -p {project}/runs\n",
        "%tensorboard --logdir={project}/runs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a3d7c5cf-66b4-42e1-a14f-1003b88ced9b",
      "metadata": {
        "tags": [],
        "id": "a3d7c5cf-66b4-42e1-a14f-1003b88ced9b"
      },
      "outputs": [],
      "source": [
        "from torchvision.utils import make_grid\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from tqdm.notebook import trange\n",
        "\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import re\n",
        "\n",
        "dirpath = Path(f'{project}/runs')\n",
        "experiments = [0]\n",
        "for exp in dirpath.iterdir():\n",
        "    if exp.is_dir():\n",
        "        m = re.match(r'.*\\/exp([0-9]+)', str(exp))\n",
        "        if bool(m):\n",
        "            experiments.append(int(m.groups()[0]))\n",
        "\n",
        "exp_n = np.max(experiments) + 1\n",
        "writer = SummaryWriter(f'{project}/runs/exp{exp_n:03d}_{bs}_{lr}')\n",
        "\n",
        "n_epoch = 300\n",
        "\n",
        "for epoch in trange(1, n_epoch + 1):\n",
        "    D_losses, G_losses = [], []\n",
        "\n",
        "    for batch_idx, (x, _) in enumerate(train_loader):\n",
        "        D_losses.append(D_train(x))\n",
        "        G_losses.append(G_train(x))\n",
        "\n",
        "    writer.add_scalar('Loss/Generator', torch.mean(torch.FloatTensor(G_losses)), epoch)\n",
        "    writer.add_scalar('Loss/Discriminator', torch.mean(torch.FloatTensor(D_losses)), epoch)\n",
        "    with torch.no_grad():\n",
        "        fake_z = torch.randn(bs, z_dim).to(device)\n",
        "        generated = G(fake_z)\n",
        "        generated = (generated + 1) / 2\n",
        "    fake_image = make_grid(generated[0:25].view(25, 1, 28, 28), nrow=5)\n",
        "    writer.add_image('Fake Image', fake_image, epoch)\n",
        "\n",
        "writer.flush()\n",
        "writer.close()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hA0p97qZtDlu"
      },
      "id": "hA0p97qZtDlu",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.10"
    },
    "colab": {
      "name": "mnist-gan-pytorch.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}